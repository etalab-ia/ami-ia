{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/ami_ia_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNBVSFaLObUS"
   },
   "source": [
    "# Notebook NLP\n",
    "\n",
    "Introduction au NLP avec l'example des avis rendus par la CADA (Comission d'Accès aux Documents Administratifs)\n",
    "L'objectif de ce notebook est présenter des exemples d'utilisation de modèles de traitement du langage naturel, à partir d'un jeu de données textuelles. Nous allons analyser les avis CADA et tenter de répondre à deux questions: \n",
    "\n",
    "### 1- Puis-je dégager les thèmes principaux traités par les avis CADA? \n",
    "### 2 - Puis-je classer automatiquement les avis en avis Favorable / Défavorable à partir du texte de l'avis? \n",
    "\n",
    "Concernant la première question, on se met dans la peau d'un agent de la CADA, qui doit faire un rapport présentant les principaux thèmes abordés dans les avis CADA, et la proportion représentée par chacun de ces thèmes. \n",
    "\n",
    "Concernant la deuxième question, l'intérêt de ce type d'analyse serait de vérifier automatiquement la cohérence des métadonnées. Est-ce qu'un avis classé dans le SI comme favorable correspond bien à un avis défavorable au regard du texte de l'avis. \n",
    "\n",
    "\n",
    "A la fin du notebook, on présente quelques étapes classiques de traitement de langage naturel. \n",
    "\n",
    "La page de data.gouv où l'on peut télécharger les données est ici: https://www.data.gouv.fr/fr/datasets/avis-et-conseils-de-la-cada/ . L'url de téléchargement des données utilisées ici est https://www.data.gouv.fr/fr/datasets/r/93aed7ce-db2f-4982-8127-340562061e4b . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0: Analyses simples du jeu de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importation des libraries utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dC4ECExRSWdV"
   },
   "outputs": [],
   "source": [
    "# pour la manipulation de jeux de données \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# commandes pour éliminer les warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pour la dataviz \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture du jeu de données à partir de l'url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gog_D9PYOlS3"
   },
   "outputs": [],
   "source": [
    "# lire le jeu de données en un objet \"pandas dataframe\"\n",
    "df = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/ff3d14f4-b19b-4c33-a03c-e7819223da93\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel est le nombre de lignes et le nombre de colonnes de mon jeu de données ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les types des colonnes mon jeu de données? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quoi ressemble mon jeu de données ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les variables catégorielles: \n",
    "- combien de valeurs remplies (count), \n",
    "- combien de valeurs uniques / modalités (unique), \n",
    "- quelle est la modalité la plus représentée (top), \n",
    "- quelle est le nombre de fois où apparait la modalité la plus représentée (freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du nombre d'avis par année"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on crée une dataframe avec une ligne par année, la colonne count donne le nombre d'avis par année \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"] = 1\n",
    "dfg = df.groupby(\"Année\").agg(\"sum\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(dfg['Année'], dfg['count'], 'b-')\n",
    "plt.xlabel('Année'); plt.ylabel(\"Nombre d'avis\"); plt.title(\"Nombre d'avis CADA par année\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il y a très peu d'avais avant 2012, et donc que la majorité des avis sont pour la période 2012-2020\n",
    "Commbien d'avis sont compris dans cette période 2012-2020? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre d'avis dans 20012-2020 :  {}\".format(len(df[df[\"Année\"].isin(range(2012, 2020))])))\n",
    "print(\"Proportion d'avis dans 20012-2020 :  {}\".format(len(df[df[\"Année\"].isin(rang\n",
    "                                                                               e(2012, 2020))])/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : topic extraction (non supervisé)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un algorithme d'extraction de topiques: LDA (Latent Dirichlet Allocation) \n",
    "\n",
    "### ressource : article très pédagogique (en anglais) dont on s'inspire ici https://towardsdatascience.com/the-complete-guide-for-topics-extraction-in-python-a6aaa6cedbbc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quoi sert cet algorithme?\n",
    " \n",
    "LDA est un algorithme d'extraction de topics. A partir d'un corpus de documents, il permet de : \n",
    "- définir un nombre de topics (un topic est caractérisé par une liste de mots)\n",
    "- attribuer à chaque document un ou des topics de la liste de topics trouvés par l'algorithme \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![illustration_LDA.png](./images/illustration_LDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel est l'intérêt pour l'analyse des données CADA? \n",
    "\n",
    "Dans le jeu de données, nous avons la colonne \"Thème et sous thème\". On se met dans la situation où on a perdu cette colonne (pour tout ou une partie des données). On a besoin d'avoir une idée des thématiques abordées dans les avis rendus par la CADA. Une analyse automatique nous permet de réaliser cet objectif. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 0 : importation de la librairie avec l'algorithme \n",
    "#!pip install gensim si ce n'est pas déjà fait \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from gensim import models\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 1 :préparation et nettoyage des données textuelles \n",
    "\n",
    "- tokenization \n",
    "- supression de la ponctuation (pour certains cas d'usage, il peut cependant être utile de garder la ponctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la tokenisation, nous l'avons déjà calculée dans la partie 1 (les tokens sont dans la colonne \"avis_word_token\". \n",
    "On supprime la ponctuation avec la commande ci-desous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on retire les Avis \"vides\"\n",
    "df = df.dropna(subset = [\"Avis\"]) \n",
    "# on tokenize \n",
    "df[\"avis_word_token\"] = df[\"Avis\"].map(lambda x : word_tokenize(x.replace(\"'\", \" \"))) # on remplace les appostrophes par un espaces\n",
    "# car la tokenization avec la fonction \"word_tokenize\" de nltk ne les sépare pas autrement \n",
    "df[\"avis_word_token\"] = df[\"avis_word_token\"].map(lambda list_word: [word.lower()  for word in list_word if word.isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les stopwords (les mots très courants et qui n'apportent pas d'informations spécifiques pour caractériser le thème du document)\n",
    "Pour cela, on utilise une liste prédéfinie de stopwords de la librairie nltk, que l'on complète avec un certain nombre de stopwords. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la liste de stopwords\n",
    "custom_stopwords = [\"a\", \"dont\", \"madame\", \"monsieur\", \"peut\", \"dès\", \"lors\", \"être\", \"ce\",\n",
    "                    \"ces\", \"cet\", \"cette\", \"comme\", \"ainsi\", \"si\"]\n",
    "stopwords_fr = stopwords.words('french') + custom_stopwords\n",
    "print(len(stopwords_fr))\n",
    "#print(stopwords_fr)\n",
    "\n",
    "# on enlève les stopwords\n",
    "df[\"avis_word_token\"] = df[\"avis_word_token\"].map(lambda list_word: [word for word in list_word if word not in stopwords_fr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde ce que ça donne (différence entre notre document initial et la liste des tokens \"netoyés\"). \n",
    "Vous pouvez changer le numero_doc (modifier le chiffre après le = ) et exécuter la cellule pour visualiser un autre document du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_doc = 0\n",
    "\n",
    "print(\"Document initial\")\n",
    "print(df.loc[numero_doc, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Document tokénisé\")\n",
    "print(df.loc[numero_doc, \"avis_word_token\"])\n",
    "print(\"\\n\")\n",
    "print(\"Nombre de token dans le doc :{}\".format(len(df.loc[numero_doc, \"avis_word_token\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 2: Entrainement de l'algorithme \n",
    "\n",
    "Dans l'étape ci-dessous, nous allons, à partir de notre liste de tokens netoyés, créer des bigrammes. Les bigrammes sont des paires de mots, qui peuvent être porteurs de sens et qui sont donc utile pour le topic extraction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des tokens avec bigrammes \n",
    "tokens = df['avis_word_token'].tolist()\n",
    "bigram_model = Phrases(tokens)\n",
    "tokens = list(bigram_model[tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle après avoir constitué: \n",
    "- le dictionnaire des mots du corpus (ici les tokens \"simples\" (monogrammes) et bigrammes )\n",
    "- le corpus au format spécique du modèle LDA de gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_LDA = corpora.Dictionary(tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(tok) for tok in tokens]\n",
    "\n",
    "\n",
    "\n",
    "# les inputs : le corpus de documents tokenizé et le dictionnaire \n",
    "# (liste des mots apparaissant dans le dictionnaire)\n",
    "\n",
    "np.random.seed(123456)\n",
    "num_topics = 15\n",
    "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                  id2word=dictionary_LDA, \\\n",
    "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                  eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 3 : Visualisation des topics \n",
    "\n",
    "Dans un premier temps, on peut visualiser les topics de façon très \"brute\" sous forme de listes de termes qui caractérisent chaque topic. L'interprétation de ces topics demande une réfléxion \"humaine\" pour les rendre intelligibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec 15 topics \n",
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemples d'interprétation des topics ci-dessus:\n",
    "- topic 0: difficile à interpréter, topic un peu \"fourre-tout\"\n",
    "- topic 1: relation entre administration et personnes privées\n",
    "- topic 2: dossiers médicaux \n",
    "- topic 3: mairie et conseil municipal \n",
    "- topic 4: sécurité sociale \n",
    "- topic 5: santé publique \n",
    "etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 4 : Attribution des topics aux documents \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution des topics pour un document en particulier (faire varier le numéro entre crocher puis refaire tourner la cellule pour voir comment évolue le résultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda_model[corpus[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant attribuer les topics du LDA à l'ensemble des documents, en rajoutant une colonne \"topic_list\" au jeu de données initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_list\"] = [lda_model[i] for i in corpus]\n",
    "# la commande ci dessus nous permet, pour chaque document, d'obtenir une liste de topics avec les probabilités associées \n",
    "# que chaque document appartienne \n",
    "df[\"main_topic\"] = df[\"topic_list\"].map(lambda list_topic: list_topic[0][0])\n",
    "df[\"main_topic_proba\"] = df[\"topic_list\"].map(lambda list_topic: list_topic[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde le nombre de documents par \"topic majoritaire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nombre_documents\"] = 1\n",
    "df_topic = df.groupby([\"main_topic\"])[\"nombre_documents\"].count().sort_values(ascending = False).reset_index()\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 5 : Eventuellement retour à l'étape 1 (en modifiant les étapes de netoyages) et 2 (en testant différents paramètres, avec en particulier le nombre de topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 6: Visualisation interactive des topics avec la librairie pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n",
    "pyLDAvis.enable_notebook()\n",
    "%time  pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 :  prédiction de la conclusion de la décision à partir du texte de l'avis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie précédente présentait un exemple de modèle non supervisé à partir de données textuelles. Des modèles non supervisés ont l'avantage de pouvoir être entrâiné à partir d'un ensemble de documents textuels \"bruts\". \n",
    "Nous présentons ici un exemple de modèle non supervisé. Il faut alors, en plus du texte brut, avoir une variable \"à prédire\". Dans beaucoup de cas, cette variable \"à prédire\" n'est pas directement disponible et il faut la construire (en annotant ou labelisant à la main les documents). Ici nous allons considérer la variable \"Sens et motivation\", qui renseigne la conclusion de l'avis rendu par la Cada. Nous allons voir si nous arrivons à entraîner un modèle à prédire, à partir du texte de la décision, à prédire la conclusion de l'avis. \n",
    "\n",
    "L'intérêt: on peut imaginer que le \"Sens et motivation\" est parfois renseigné de façon erronée et donc vérifier de façon automatique la cohérence de ce qui est renseigné. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# librairies de machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Première étape: simplifier la colonne \"sens et motivation\" en un petit nombre de catégorie\n",
    "\n",
    "La colonne \"Sens et motivation\" comporte 3094 modalités (valeurs distinctes) comme vu dans la partie 0 de description des données. Etant donnée que notre jeu de données comporte 38 000 lignes, il y a donc relativement peu d'observations en moyenne par modalité. \n",
    "Il est donc préférable de simplifier la colonne \"Sens et motivation\" afin d'obtenir un nombre beaucoup plus restreint de modalités à prédire. \n",
    "Pour cela, nous allons donc tokeniser le texte de cette colonne afin de regarder quels sont les termes qui apparaissent le plus grand nombre de fois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"Sens et motivation\"]) # on supprime les colonnes qui n'ont pas de valeur pour sens et motivation\n",
    "df[\"sens_token\"] = df[\"Sens et motivation\"].map(lambda x: word_tokenize(x.lower().replace(\"'\", \" \").replace(\"/\", \" \")))\n",
    "df[\"nb_tokens_motivation\"] = df[\"sens_token\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde combien de tokens par observation sont contenus dans la colonne \"Sens et motivation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nb_tokens_motivation\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici la matrice TF à l'aide de la même fonction que celle utilisée en partie 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(df[\"Sens et motivation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))\n",
    "dict_vocabulary = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retient les 4 catégories suivantes: \n",
    "    - défavorable\n",
    "    - favorable\n",
    "    - incompétence \n",
    "    - irrecevable \n",
    "    - sans object \n",
    "    \n",
    "La fonction \"sens_categorie\" écrite ci-dessous permet de calculer cette nouvelle variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sens_categorie(x): \n",
    "    if \"défavorable\" in x: \n",
    "        return \"defavorable\"\n",
    "    elif \"favorable\" in x: \n",
    "        return \"favorable\"\n",
    "    elif \"incompétence\" in x: \n",
    "        return \"incompetence\"\n",
    "    elif \"irrecevable\" in x: \n",
    "        return \"incompetence\"\n",
    "    elif (\"sans\" in x) and (\"objet\" in x):\n",
    "        return \"sans_objet\"\n",
    "    else: \n",
    "        return \"autre\"\n",
    "    \n",
    "df[\"sens_categorie\"] = df[\"sens_token\"].map(sens_categorie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sens_categorie\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle en utilisant comme features explicatives\n",
    " - term frequency matrix \n",
    " - tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"avis_word_token\"].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train / test data \n",
    "text_train, text_test, y_train, y_test = train_test_split(df[\"text\"], df[\"sens_categorie\"], test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First : tf matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 10).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(MultinomialNB(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 12, 14, 16, 20, 30, 40]}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second : tf-idf matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df = 15).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "scores = cross_val_score(MultinomialNB(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 0.2, 0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 1, 10, 12, 14, 16, 20, 30, 40]}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 4 : Pour aller plus loin:  manipulations de données textuelles basiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importation des librairies NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on étudie ici les textes des avis, \n",
    "on supprime les lignes pour lesquelles l'avis n'est pas renseigné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"Avis\"]) \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage du texte \n",
    "Chaque avis (dans la colonne \"Avis\") est une chaîne de caractères, il faut donc lui appliquer un certain nombre d'opération afin de pouvoir la traiter algorithmiquement. Une première étape, la tokenization, consiste en découper la chaine de caractères en \"tokens\". Pour cela, on utilise des fonctions prédéfinies de la librairies NLTK. \n",
    "Il existe plusieurs métodes de tokenization, et le choix de la méthode va dépendre de l'objectif de l'étude. \n",
    "Les métodes les plus classques sont: \n",
    "- la tokenisation en phrases (sentence tokenization en anglais)\n",
    "- la tokenisation en mots (word tokenization en anglais)\n",
    "\n",
    "\n",
    "On crée ici deux nouvelles colonnes, correspondant à ces deux modes de tokenization \n",
    "\n",
    "### Le terme consacré en NLP pour ce découpage est la tokénisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avis_sent_token\"] = df[\"Avis\"].map(sent_tokenize)\n",
    "df[\"avis_word_token\"] = df[\"Avis\"].map(lambda x : word_tokenize(x.replace(\"'\", \" \"))) # on remplace les appostrophes par un espaces\n",
    "# car la tokenization avec la fonction \"word_tokenize\" de nltk ne les sépare pas autrement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on regarde ce que ça donne : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_ligne = 1 # changer le nombre afin de visualiser différentes lignes du jeu de données \n",
    "print(\"Texte initial de l'avis\")\n",
    "print(df.loc[numero_ligne, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Texte tokenizé en phrases\")\n",
    "print(\"Nombre de phrases : {}\".format(len(df.loc[numero_ligne, \"avis_sent_token\"])))\n",
    "print(df.loc[numero_ligne, \"avis_sent_token\"])\n",
    "print(\"\\n\")\n",
    "print(\"Texte tokenizé en mots\")\n",
    "print(\"Nombre de mots : {}\".format(len(df.loc[numero_ligne, \"avis_word_token\"])))\n",
    "\n",
    "print(df.loc[numero_ligne, \"avis_word_token\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on calcule des métriques simples : \n",
    "- le nombre de caractères par avis\n",
    "- le nombre de phrases par avis \n",
    "- le nombre de mots par avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nb_char\"] = df[\"Avis\"].map(len)\n",
    "df[\"nb_sent_token\"] = df[\"avis_sent_token\"].map(len)\n",
    "df[\"nb_word_token\"] = df[\"avis_word_token\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on regarde la moyenne, l'écart type, les quartiles de ces métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[[\"nb_char\", \"nb_word_token\", \"nb_sent_token\" ]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "une fois qu'on a divisé notre texte en une liste de mots, on peut faire plusieurs opérations de netoyage \n",
    "- retirer la ponctuation \n",
    "- mettre tous les caractères en minuscules (peut aussi être fait avant la tokenization)\n",
    "- enlever les stopwords (mots sans apport pour comprendre le sens de la phrase)\n",
    "- lemmatiser ou stemmer afin de regrouper deux termes proches en un terme unique : \n",
    "    - personnes -> personne\n",
    "    - conduisent, conduis, etc.. -> conduire\n",
    "    \n",
    "Ces étapes sont réalisées dans la partie 2 : extraction de topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on peut ensuite \"vectoriser ces listes de mots afin de les rendre intelligible par une machine, \n",
    "il existe plusieurs méthode de vectoriser \n",
    "    - la matrice de term frequency \n",
    "    - la matrice tf-idf\n",
    "    - les word embeddings \n",
    "    \n",
    "Une fois que ces documents sont vectorisés, on peut utiliser ces features numériques nouvellement crées pour faire de la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressource: un article (en anglais) bien fait qui montre comment calculer la matrice TF et TF-IDF \"form scratch: cratch : https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer automatiquement ces matrices, il existe différentes librairies. On utilise ici la librairie sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matrice de term frequency (matrice d'occurrence de termes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![term_doc_matrix.png](./images/term_doc_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque document est composé d'un certains nombre de mots. L'ensemble de tous les mots distincts présents dans les documents consititue le vocabulaire du corpus (corpus = ensemble des documents). \n",
    "La term-frequency matrix est une matrice avec une ligne par document et une colonne par mot du vocabulaire. \n",
    "Pour chaque document, les colonnes donne le nombre de fois où le mot apparait dans le document. \n",
    "C'est l'approche qu'on appelle souvent \"bag of words\" ou sac de mots en français. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous on calcule la matrice Term frequency à l'aide de la librairie sklearn, qui comprend un modèle \"CountVectorizer\", qui'il faut entraîner sur le corpus de données (la liste des avis). Une fois le modèle entrainé, on l'applique (avec la métode transform) sur le même corpus de données. \n",
    "Un paramètre utile au modèle CountVectorizer est \"min_df\", qui correspond au minumum de fois où un mot doit apparaitre dans le corpus afin d'être pris en compte dans la matrice. Il est par défaut à 1, mais en l'augmentant, on peut réduire considérablement le nomnbre de colonnes de la matrice et donc se débarrasser des termes qui apparaissent trop peu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 15).fit(df[\"Avis\"])\n",
    "tf_matrix = vect.transform(df[\"Avis\"])\n",
    "print(\"TF-Matrix:\\n{}\".format(repr(tf_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Nombre de features: {}\".format(len(feature_names)))\n",
    "print(\"Les 20 premières features:\\n{}\".format(feature_names[:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour visualiser la matrice, on la transforme en dataframe: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataframe = pd.SparseDataFrame(tf_matrix, columns = feature_names).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tf_dataframe[\"être\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe ce que l'on appelle une matrice sparse, ce qui signifie que la majorité des termes sont à 0.\n",
    "On voit par exemple que les documents 3 et 4 ont chacun une fois le mot \"être\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut regarder quels sont les termes les plus fréquents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = tf_matrix.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matrice tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfidf_matrix.png](./images/tfidf_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice TF-IDF est très similaire dans son principe à la matrice TF. Elle a le même format: une ligne par document et une colonne par mot du vocabulaire. Chaque \"case\" de la matrice sera calculée à partir de la case la matrice TF, mais sera pondérée par l'IDF (inverse document frequency). Cette pondération permet de prendre en compte la fréquence d'occurence d'un terme dans l'ensemble des documents (le corpus). L'idée derrière cette pondération est qu'un terme qui apparait dans un très grand nombre de document n'apporte pas beaucoup d'information pour décrire un document en particulier. Par exemple, dans notre cas, le mot \"avis\" apparait dans quasiment tous nos documents, il aura donc une fréquence d'apparition dans le corpus élevé et donc un IDF (son inverse) faible. \n",
    "\n",
    "Pour résumer, pour un mot donné d'un document donné, le TF-IDF: \n",
    "\n",
    "- augmente avec le nombre d'occurrences du mot dans le document\n",
    "- diminue avec le nombre d'occirrences du mot dans le corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = TfidfVectorizer(min_df = 15).fit(df[\"Avis\"])\n",
    "tfidf_matrix = vect2.transform(df[\"Avis\"])\n",
    "print(\"TF-Matrix:\\n{}\".format(repr(tf_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect2.get_feature_names()\n",
    "print(\"Nombre de features: {}\".format(len(feature_names)))\n",
    "print(\"Les 20 premières features:\\n{}\".format(feature_names[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans surprise, on obtient les mêmes features qu'avec la matrice TF. Regardons mainteant quelques lignes de cette matrice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_dense = tfidf_matrix.todense()\n",
    "tfidf_matrix_dense[tfidf_matrix_dense == 0] = np.nan\n",
    "mean_words = np.nanmean(tfidf_matrix_dense, axis=0)\n",
    "words_mean_tfidf = [(word, mean_words[0, idx]) for word, idx in vect2.vocabulary_.items()]\n",
    "words_freq =sorted(words_mean_tfidf, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est intéressant de comparer ici les termes remontés avec la matrice TF et ceux avec la matrice TFIDF. La matrice TF remonte beaucoup de termes \"inutiles\" (de, et, etc...), alors que la matrice TFIDF remonte des termes plus intéressants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dataframe = pd.SparseDataFrame(tfidf_matrix, columns = feature_names).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on voit que le terme \"être\" est encore non nul pour les document 3 et 4, mais nous avons des nombres décimals au lieu de nombres entiers. \n",
    "\n",
    "\\begin{align}\n",
    " {\\mathrm {tfidf_{{i,j}}}}={\\mathrm {tf_{{i,j}}}}\\cdot {\\mathrm {idf_{{i}}}} \\\\\n",
    " {\\mathrm {tfidf_{{être,3}}}} = 1\\cdot {\\mathrm {idf_{{être}}}} =1\\cdot 0.070411 \\\\\n",
    "\\end{align}\n",
    "\n",
    "On en déduit que: \n",
    "\\begin{align}\n",
    " {\\mathrm {idf_{{être}}}} = 0.070411 \\\\\n",
    "\\end{align}\n",
    "\n",
    "Définition de l'IDF:  \n",
    "\\begin{align}\n",
    " {\\mathrm {idf_{{i,j}}}} = {\\mathrm {log_{{10}}}} {\\|D\\| \\over \\| \\{ d_{j} : t_{i} \\in d_{j} \\} \\| } \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "len(df)/math.pow(10, 0.070411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_dataframe[tfidf_dataframe[\"être\"]>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de word embeddings of word2vec\n",
    "\n",
    "A propos de word2vec: développé par une équipe de recherche de Google (article de 2013 disponible ici https://arxiv.org/abs/1301.3781), word2vec est un algorithme permettant de reprénter chaque mot dans un espace vectoriel à n dimensions (généralement n est fixé dans une valeur comprise entre 100 et 400). Les vecteurs des différents mots sont \"appris\" à l'aide d'un réseau de neurone artificiel. Ces vecteurs, appelés \"word embeddings\", permettent: \n",
    "- de rendre compte des proximités des mots dans le langage naturel (deux mots proches dans le langage, médecin et hopitaux, seront proches dans l'espace vectoriel) \n",
    "- de traduire certaines proprités linguistiques du langage naturel en propriétés mathématiques (cf. exemples dans illustration ci-dessous)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word2vec.png](./images/word2vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle à partir du texte des avis Cada. Les paramètres à fixer sont: \n",
    "- size: la taille de l'espace vectoriel (le nombre de dimensions de chaque vecteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"avis_word_token\"].tolist()\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de vecteur pour un mot donné (vous pouvez changer le mot entre guillements et voir les variations des vecteurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['avis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quelques exemples de calculs des mots les plus similaires, en utilisant la fonction méthode \"most_similar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"médecin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"maire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.most_similar(\"demande\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEL6x0Kfsdvmbf+E371X9g",
   "include_colab_link": true,
   "name": "ami_ia-NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
