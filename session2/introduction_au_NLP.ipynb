{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/ami_ia_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNBVSFaLObUS"
   },
   "source": [
    "# Notebook NLP\n",
    "\n",
    "Introduction au NLP avec l'example des avis rendus par la CADA (Comission d'Accès aux Documents Administratifs)\n",
    "L'objectif de ce notebook est présenter des exemples d'utilisation de modèles de traitement du langage naturel, à partir d'un jeu de données textuelles. Nous allons analyser les avis CADA et tenter de répondre à deux questions: \n",
    "\n",
    "### 1- Puis-je dégager les thèmes principaux traités par les avis CADA? \n",
    "### 2 - Puis-je classer automatiquement les avis en avis Favorable / Défavorable à partir du texte de l'avis? \n",
    "\n",
    "Concernant la première question, on se met dans la peau d'un agent de la CADA, qui doit faire un rapport présentant les principaux thèmes abordés dans les avis CADA, et la proportion représentée par chacun de ces thèmes. \n",
    "\n",
    "Concernant la deuxième question, l'intérêt de ce type d'analyse serait de vérifier automatiquement la cohérence des métadonnées. Est-ce qu'un avis classé dans le SI comme favorable correspond bien à un avis défavorable au regard du texte de l'avis. \n",
    "\n",
    "\n",
    "A la fin du notebook, on présente quelques étapes classiques de traitement de langage naturel. \n",
    "\n",
    "La page de data.gouv où l'on peut télécharger les données est ici: https://www.data.gouv.fr/fr/datasets/avis-et-conseils-de-la-cada/ . L'url de téléchargement des données utilisées ici est https://www.data.gouv.fr/fr/datasets/r/93aed7ce-db2f-4982-8127-340562061e4b . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 0: Analyses simples du jeu de données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importation des libraries utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dC4ECExRSWdV"
   },
   "outputs": [],
   "source": [
    "# pour la manipulation de jeux de données \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# commandes pour éliminer les warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pour la dataviz \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture du jeu de données à partir de l'url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gog_D9PYOlS3"
   },
   "outputs": [],
   "source": [
    "# lire le jeu de données en un objet \"pandas dataframe\"\n",
    "df = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/ff3d14f4-b19b-4c33-a03c-e7819223da93\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel est le nombre de lignes et le nombre de colonnes de mon jeu de données ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les types des colonnes mon jeu de données? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quoi ressemble mon jeu de données ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus, le texte des avis est tronqué, nous allons donc regarder un avis complet à l'aide de la commande ci-dessous(changer le numero après le \"numero_doc = \" puis réexécuter la cellule afin de visualiser un nouvel exemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_doc = 30000\n",
    "print(\"Date de l'avis\")\n",
    "print(df.loc[numero_doc, \"Séance\"])\n",
    "print(\"\\n\")\n",
    "print(\"Texte de l'avis\")\n",
    "print(df.loc[numero_doc, \"Avis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde les variables catégorielles: \n",
    "- combien de valeurs remplies (count), \n",
    "- combien de valeurs uniques / modalités (unique), \n",
    "- quelle est la modalité la plus représentée (top), \n",
    "- quelle est le nombre de fois où apparait la modalité la plus représentée (freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du nombre d'avis par année"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une dataframe avec une ligne par année, la colonne count donne le nombre d'avis par année.\n",
    "On va utilise la librairie matplotlib pour tracer le graphe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la dataframe agrégée au niveau de l'année \n",
    "df[\"count\"] = 1\n",
    "dfg = df.groupby(\"Année\").agg(\"sum\").reset_index()\n",
    "\n",
    "# commandes pour tracer le graphe \n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(dfg['Année'], dfg['count'], 'b-')\n",
    "plt.xlabel('Année'); plt.ylabel(\"Nombre d'avis\"); plt.title(\"Nombre d'avis CADA par année\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'il y a très peu d'avais avant 2012, et donc que la majorité des avis sont pour la période 2012-2020\n",
    "Commbien d'avis sont compris dans cette période 2012-2020? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre d'avis dans 20012-2020 :  {}\".format(len(df[df[\"Année\"].isin(range(2012, 2020))])))\n",
    "print(\"Proportion d'avis dans 20012-2020 :  {}\".format(len(df[df[\"Année\"].isin(range(2012, 2020))])/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : topic extraction (non supervisé)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un algorithme d'extraction de topiques: LDA (Latent Dirichlet Allocation) \n",
    "\n",
    "### ressource : article très pédagogique (en anglais) dont on s'inspire ici https://towardsdatascience.com/the-complete-guide-for-topics-extraction-in-python-a6aaa6cedbbc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quoi sert cet algorithme?\n",
    " \n",
    "LDA est un algorithme d'extraction de topics. A partir d'un corpus de documents, il permet de : \n",
    "- définir un nombre de topics (un topic est caractérisé par une liste de mots)\n",
    "- attribuer à chaque document un ou des topics de la liste de topics trouvés par l'algorithme \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![illustration_LDA.png](./images/illustration_LDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel est l'intérêt pour l'analyse des données CADA? \n",
    "\n",
    "Dans le jeu de données, nous avons la colonne \"Thème et sous thème\". Cependant, cette donnée a une granularité beaucoup trop fine: il y 828 valeurs distinctes dans cette variable. \n",
    "\n",
    "On a besoin d'avoir une idée des thématiques abordées dans les avis rendus par la CADA, avec un nombre plus restreint de modalités. Une analyse automatique nous permet de réaliser cet objectif. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape 0 : importation de la librairie avec l'algorithme \n",
    "#!pip install gensim si ce n'est pas déjà fait \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from gensim import models\n",
    "from gensim.models import Phrases\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 1 :préparation et nettoyage des données textuelles \n",
    "\n",
    "- tokenization (découpage du texte initial en mots)\n",
    "- supression de la ponctuation (pour certains cas d'usage, il peut cependant être utile de garder la ponctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la tokenisation, nous utilisons une fonction de la librairie NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on retire les Avis \"vides\"\n",
    "df = df.dropna(subset = [\"Avis\"]) \n",
    "# on tokenize \n",
    "df[\"avis_word_token\"] = df[\"Avis\"].map(lambda x : word_tokenize(x.replace(\"'\", \" \"))) # on remplace les appostrophes par un espaces\n",
    "# car la tokenization avec la fonction \"word_tokenize\" de nltk ne les sépare pas autrement \n",
    "df[\"avis_word_token\"] = df[\"avis_word_token\"].map(lambda list_word: [word.lower()  for word in list_word if word.isalpha()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les stopwords (les mots très courants et qui n'apportent pas d'informations spécifiques pour caractériser le thème du document)\n",
    "Pour cela, on utilise une liste prédéfinie de stopwords de la librairie nltk, que l'on complète avec un certain nombre de stopwords. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de la liste de stopwords\n",
    "custom_stopwords = [\"a\", \"dont\", \"madame\", \"monsieur\", \"peut\", \"dès\", \"lors\", \"être\", \"ce\",\n",
    "                    \"ces\", \"cet\", \"cette\", \"comme\", \"ainsi\", \"si\"]\n",
    "stopwords_fr = stopwords.words('french') + custom_stopwords\n",
    "print(len(stopwords_fr))\n",
    "#print(stopwords_fr)\n",
    "\n",
    "# on enlève les stopwords\n",
    "df[\"avis_word_token\"] = df[\"avis_word_token\"].map(lambda list_word: [word for word in list_word if word not in stopwords_fr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde ce que ça donne (différence entre notre document initial et la liste des tokens \"netoyés\"). \n",
    "Vous pouvez changer le numero_doc (modifier le chiffre après le = ) et exécuter la cellule pour visualiser un autre document du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_doc = 0\n",
    "\n",
    "print(\"Document initial\")\n",
    "print(df.loc[numero_doc, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Document tokénisé\")\n",
    "print(df.loc[numero_doc, \"avis_word_token\"])\n",
    "print(\"\\n\")\n",
    "print(\"Nombre de token dans le doc :{}\".format(len(df.loc[numero_doc, \"avis_word_token\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 2: Entrainement de l'algorithme \n",
    "\n",
    "Dans l'étape ci-dessous, nous allons, à partir de notre liste de tokens netoyés, créer des bigrammes. Les bigrammes sont des paires de mots, qui peuvent être porteurs de sens et qui sont donc utile pour le topic extraction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des tokens avec bigrammes \n",
    "tokens = df['avis_word_token'].tolist()\n",
    "bigram_model = Phrases(tokens)\n",
    "tokens = list(bigram_model[tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle après avoir constitué: \n",
    "- le dictionnaire des mots du corpus (ici les tokens \"simples\" (monogrammes) et bigrammes )\n",
    "- le corpus au format spécique du modèle LDA de gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_LDA = corpora.Dictionary(tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(tok) for tok in tokens]\n",
    "\n",
    "\n",
    "\n",
    "# les inputs : le corpus de documents tokenizé et le dictionnaire \n",
    "# (liste des mots apparaissant dans le dictionnaire)\n",
    "\n",
    "np.random.seed(123456)\n",
    "num_topics = 15\n",
    "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                  id2word=dictionary_LDA, \\\n",
    "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                  eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 3 : Visualisation des topics \n",
    "\n",
    "Dans un premier temps, on peut visualiser les topics de façon très \"brute\" sous forme de listes de termes qui caractérisent chaque topic. L'interprétation de ces topics demande une réfléxion \"humaine\" pour les rendre intelligibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec 15 topics \n",
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A vous de jouer ! Essayer de donner une interprétation intelligibles des topics décrits par les listes de termes ci-dessus: \n",
    "- topic 0: \n",
    "- topic 1:\n",
    "- topic 2:\n",
    "- topic 3: \n",
    "- topic 4:\n",
    "- topic 5: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 4 : Attribution des topics aux documents \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution des topics pour un document en particulier (faire varier le numéro entre crocher puis refaire tourner la cellule pour voir comment évolue le résultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_doc = 1\n",
    "print(\"Texte de l'avis numéro {}\".format(numero_doc))\n",
    "print(df.loc[numero_doc, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Topics et probilités associées\")\n",
    "print(lda_model[corpus[numero_doc]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant attribuer les topics du LDA à l'ensemble des documents, en rajoutant une colonne \"topic_list\" au jeu de données initial\n",
    "Cette colonne va nous donner une liste de topics est la probabilité que le document appartienne à chacun des topics de la liste. \n",
    "Par exemple, dans l'exemple ci-dessous, le document est caractérisé par 6 des 15 topics. Le topic \"majoritaire\" (ie celui avec la plus forte probabilité) est le topic 9, avec une probabilité associée de 0.43. \n",
    "Nous calculons également les colonnes suivantes :\n",
    "- \"main_topic\": le topic majoritaire (ie celui avec la plus forte probabilité)\n",
    "- \"main_topic_proba\": la probabilté que le document appartienne au topic majoritaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"topic_list\"] = [lda_model[i] for i in corpus]\n",
    "# la commande ci dessus nous permet, pour chaque document, d'obtenir une liste de topics avec les probabilités associées \n",
    "# que chaque document appartienne \n",
    "def topic_majoritaire(list_topic, is_proba): \n",
    "    proba = [x[1] for x in list_topic]\n",
    "    max_index = proba.index(max(proba))\n",
    "    return list_topic[max_index][is_proba]\n",
    "df[\"main_topic\"] = df[\"topic_list\"].map(lambda list_topic: topic_majoritaire(list_topic, 0))\n",
    "df[\"main_topic_proba\"] = df[\"topic_list\"].map(lambda list_topic: topic_majoritaire(list_topic, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde le nombre de documents par \"topic majoritaire\". La sortie ci-dessous nous permet de voir pour chaque topic, combien de document lui sont associés en tant que topic majoritaire. Les topics sont classés par nombre décroissant de documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nombre_documents\"] = 1\n",
    "df_topic = df.groupby([\"main_topic\"])[\"nombre_documents\"].count().sort_values(ascending = False).reset_index()\n",
    "df_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 5 : Eventuellement retour à l'étape 1 (en modifiant les étapes de netoyages) et 2 (en testant différents paramètres, avec en particulier le nombre de topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 6: Visualisation interactive des topics avec la librairie pyLDAvis\n",
    "La librairie PyLDAvis permet de visualiser les topics extraits via un modèle LDA. \n",
    "Chaque topic est représenté dans le plan par un disque dont l'aire est proportionnelle \"l'importance\" du topic dans l'ensemble des documents (plus précisemment, la métrique utilisée ici pour caractérier l'importance du topic est la distribution marginale du topic dans le corpus). \n",
    "En cliquant sur un cercle dans la partie de gauche (représentant un topic), on obtient à droite les mots caractérisant le topic classés du plus pertinent (en haut) au moins pertinent (en bas).\n",
    "Ce classement par la pertinence (relevance en anglais) d'un mot pour un topic donné dépend d'un facteur lambda que l'on peut faire varier grâce au curseur en haut à droite. Plus lambda est proche de 0, plus les termes pertinents seront rares (mais seront exclusifs i.e. qui ne se retrouveront pas dans d'autres topics). Plus lambda est proche de 1, plus les termes pertinents seront fréquents (mais seront davantage communs à d'autres topics). \n",
    "\n",
    "\n",
    "Voir cette présentation en anglais sur cet outil de visualisation https://speakerdeck.com/bmabey/visualizing-topic-models et le papier de recherche associé https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 :  prédiction de la conclusion de la décision à partir du texte de l'avis (modèle supervisé)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie précédente présentait un exemple de modèle non supervisé à partir de données textuelles. Des modèles non supervisés ont l'avantage de pouvoir être entrâiné à partir d'un ensemble de documents textuels \"bruts\". \n",
    "Nous présentons dans cette partie un exemple de modèle supervisé. Il faut alors, en plus du texte brut, avoir une variable \"à prédire\". Dans beaucoup de cas, cette variable \"à prédire\" n'est pas directement disponible et il faut la construire (en annotant ou labelisant à la main les documents). \n",
    "\n",
    "Ici nous allons considérer la variable \"Sens et motivation\", qui renseigne la conclusion de l'avis rendu par la Cada. Nous allons voir si nous arrivons à entraîner un modèle à prédire, à partir du texte de la décision, à prédire la conclusion de l'avis. \n",
    "\n",
    "L'intérêt: on peut imaginer que le \"Sens et motivation\" est parfois renseigné de façon erronée et donc vérifier de façon automatique la cohérence de ce qui est renseigné. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# librairies de machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 1: simplifier la colonne \"sens et motivation\" en un petit nombre de catégorie\n",
    "\n",
    "La colonne \"Sens et motivation\" comporte 3094 modalités (valeurs distinctes) comme vu dans la partie 0 de description des données. Etant donnée que notre jeu de données comporte 38 000 lignes, il y a donc relativement peu d'observations en moyenne par modalité. \n",
    "Il est donc préférable de simplifier la colonne \"Sens et motivation\" afin d'obtenir un nombre beaucoup plus restreint de modalités à prédire. \n",
    "Pour cela, nous allons donc tokeniser le texte de cette colonne afin de regarder quels sont les termes qui apparaissent le plus grand nombre de fois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"Sens et motivation\"]) # on supprime les colonnes qui n'ont pas de valeur pour sens et motivation\n",
    "df[\"sens_token\"] = df[\"Sens et motivation\"].map(lambda x: word_tokenize(x.lower().replace(\"'\", \" \").replace(\"/\", \" \")))\n",
    "df[\"nb_tokens_motivation\"] = df[\"sens_token\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde combien de tokens par observation sont contenus dans la colonne \"Sens et motivation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nb_tokens_motivation\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici la matrice TF à l'aide de la même fonction que celle utilisée en partie 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(df[\"Sens et motivation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"Vocabulary content:\\n {}\".format(vect.vocabulary_))\n",
    "dict_vocabulary = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retient les 4 catégories suivantes: \n",
    "    - défavorable\n",
    "    - favorable\n",
    "    - incompétence \n",
    "    - irrecevable \n",
    "    - sans object \n",
    "    \n",
    "La fonction \"sens_categorie\" écrite ci-dessous permet de calculer cette nouvelle variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sens_categorie(x): \n",
    "    if \"défavorable\" in x: \n",
    "        return \"defavorable\"\n",
    "    elif \"favorable\" in x: \n",
    "        return \"favorable\"\n",
    "    elif \"incompétence\" in x: \n",
    "        return \"incompetence\"\n",
    "    elif \"irrecevable\" in x: \n",
    "        return \"incompetence\"\n",
    "    elif (\"sans\" in x) and (\"objet\" in x):\n",
    "        return \"sans_objet\"\n",
    "    else: \n",
    "        return \"autre\"\n",
    "    \n",
    "df[\"sens_categorie\"] = df[\"sens_token\"].map(sens_categorie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sens_categorie\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 2:  Entraînement du modèle \n",
    "Nous allons utiliser un modèle supervisé. Il nous faut donc: \n",
    "- une variable cible (ici la variable sens_catégorie que nous venons de créer et qui comporte 4 valeurs uniques) \n",
    "- des features (variables explicatives) à partir desquelles l'algorithmes va \"apprendre\" à prédire la variable cible : ici les features seront créés à partir du texte des avis\n",
    "\n",
    "La variable cible étant \"multi-modale\" (ici nous avons 4 possibilités), nous devons choisir un modèle adapté. Nous prenons ici le modèle multinomial Naive Bayes. Voir ici la description du modèle : https://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne \n",
    "\n",
    "\n",
    "![schema_supervise.png](./images/schema_supervise.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare le jeu de données en deux: \n",
    "- un jeu d'entraînement (train): text_train (ce qui va permettre de créer les features) et y_train (la variable cible du jeu d'entraînementà\n",
    "- un jeu de test : text_test (ce qui va nous permettre de créer les features) et y_test (la variable cible du jeu de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(df[\"Avis\"], df[\"sens_categorie\"], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle avec la matrice term frequency (TF) (voir Partie 3 qui présente différentes méthodes de vectorisation dont la matrice term frequency )\n",
    "\n",
    "Ci-dessous on crée la matrice TF à l'aide de la fonction CountVectorizer() de sklearn.\n",
    "Le paramètre min_df permet de ne prendre en compte que les mots qui apparaissent au moins x fois dans le corpus. Nous l'avons mis à 10 ici mais il est possible de faire varier ce paramètre et de ré-entraîner le modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 10).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes ci-dessous permettent de connaitre: \n",
    "    - le nombre total de features crées à partir du texte des avis\n",
    "    - le nom des 20 premières features\n",
    "    - le nom des 20 dernières features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Nombre de features: {}\".format(len(feature_names)))\n",
    "print(\"Premières 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Les 20 dernières features:\\n{}\".format(feature_names[-20:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle en utilisant la méthode de k-fold cross-validation avec k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(MultinomialNB(), X_train, y_train, cv=5)\n",
    "print(\"5-fold cross validation justesse (accuracy): {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation des hyper paramètre (ici l'hyper paramètre est alpha)\n",
    "\n",
    "Le concept d'**hyperparamètres** : des paramètres que le modèle ne peut pas apprendre, il est donc fixé \"manuellement\". \n",
    "\n",
    "La méthode appelée **GridSearch** permet de tester différentes valeurs d'hyperparamètre et de sélectionner la valeur donnant la meilleure performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 12, 14, 16, 20, 30, 40]}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Meilleur cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Meilleur paramètre: \", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde le score sur l'échantillon test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrice de confusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                index=['Vrai Défavorable', 'Vrai Favorable', 'Vrai Incompétence', 'Vrai Sans Objet'],\n",
    "                columns=['Prédit Défavorable', 'Prédit Favorable', 'Prédit Incompétence', 'Prédit Sans Objet'])\n",
    "\n",
    "print(\"Matrice de confusion sur le jeu de données test\")\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A vous de jouer** :  au vue de la matrice ci-dessus\n",
    "- parmi les avis prédits en défavorables, combien ont été correctement prédits ? \n",
    "- parmi les avis effectivement défavorables, combien ont été prédits en avis défavorables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all =  vect.transform(df[\"Avis\"])\n",
    "df[\"y_pred\"] = best_model.predict(X_all)\n",
    "conf_mat_all = confusion_matrix(df[\"sens_categorie\"], df[\"y_pred\"])\n",
    "\n",
    "conf_mat_all_df = pd.DataFrame(conf_mat_all, \n",
    "                index=['Vrai Défavorable', 'Vrai Favorable', 'Vrai Incompétence', 'Vrai Sans Objet'],\n",
    "                columns=['Prédit Défavorable', 'Prédit Favorable', 'Prédit Incompétence', 'Prédit Sans Objet'])\n",
    "\n",
    "print(\"Matrice de confusion sur l'ensemble train + test\")\n",
    "conf_mat_all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant regarder des exemples de valeurs mal \"prédites\" pour comprendre d'où vient le problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_doc = 0\n",
    "df[\"is_correct\"] = df.apply(lambda row: 1 if row[\"sens_categorie\"]==row[\"y_pred\"] else 0, axis = 1)\n",
    "df_errors = df[df[\"is_correct\"]==0].reset_index()\n",
    "print(df_errors.loc[numero_doc, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Conclusion de l'avis (variable initiale): {}\".format(df_errors.loc[numero_doc, \"Sens et motivation\"]))\n",
    "print(\"Conclusion de l'avis (variable simplifiée): {}\".format(df_errors.loc[numero_doc, \"sens_categorie\"]))\n",
    "print(\"Prédiction : {}\".format(df_errors.loc[numero_doc, \"y_pred\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraînement du modèle avec la matrice TF-IDF (voir Partie 3 qui présente différentes méthodes de vectorisation dont la matrice term frequency )\n",
    "Les étapes sont les mêmes que dans la partie entraînement du modèle avec la matrice term-frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df = 15).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "scores = cross_val_score(MultinomialNB(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 0.2, 0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 1, 10, 12, 14, 16, 20, 30, 40]}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Test score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 3 : visualisation des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreurs\n",
    "# exemple d'erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 : Pour aller plus loin:  manipulations de données textuelles basiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importation des librairies NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on étudie ici les textes des avis, \n",
    "on supprime les lignes pour lesquelles l'avis n'est pas renseigné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset = [\"Avis\"]) \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage du texte \n",
    "Chaque avis (dans la colonne \"Avis\") est une chaîne de caractères, il faut donc lui appliquer un certain nombre d'opération afin de pouvoir la traiter algorithmiquement. Une première étape, la tokenization, consiste en découper la chaine de caractères en \"tokens\". Pour cela, on utilise des fonctions prédéfinies de la librairies NLTK. \n",
    "Il existe plusieurs métodes de tokenization, et le choix de la méthode va dépendre de l'objectif de l'étude. \n",
    "Les métodes les plus classques sont: \n",
    "- la tokenisation en phrases (sentence tokenization en anglais)\n",
    "- la tokenisation en mots (word tokenization en anglais)\n",
    "\n",
    "\n",
    "On crée ici deux nouvelles colonnes, correspondant à ces deux modes de tokenization \n",
    "\n",
    "### Le terme consacré en NLP pour ce découpage est la tokénisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avis_sent_token\"] = df[\"Avis\"].map(sent_tokenize)\n",
    "df[\"avis_word_token\"] = df[\"Avis\"].map(lambda x : word_tokenize(x.replace(\"'\", \" \"))) # on remplace les appostrophes par un espaces\n",
    "# car la tokenization avec la fonction \"word_tokenize\" de nltk ne les sépare pas autrement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on regarde ce que ça donne : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_ligne = 1 # changer le nombre afin de visualiser différentes lignes du jeu de données \n",
    "print(\"Texte initial de l'avis\")\n",
    "print(df.loc[numero_ligne, \"Avis\"])\n",
    "print(\"\\n\")\n",
    "print(\"Texte tokenizé en phrases\")\n",
    "print(\"Nombre de phrases : {}\".format(len(df.loc[numero_ligne, \"avis_sent_token\"])))\n",
    "print(df.loc[numero_ligne, \"avis_sent_token\"])\n",
    "print(\"\\n\")\n",
    "print(\"Texte tokenizé en mots\")\n",
    "print(\"Nombre de mots : {}\".format(len(df.loc[numero_ligne, \"avis_word_token\"])))\n",
    "\n",
    "print(df.loc[numero_ligne, \"avis_word_token\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on calcule des métriques simples : \n",
    "- le nombre de caractères par avis\n",
    "- le nombre de phrases par avis \n",
    "- le nombre de mots par avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nb_char\"] = df[\"Avis\"].map(len)\n",
    "df[\"nb_sent_token\"] = df[\"avis_sent_token\"].map(len)\n",
    "df[\"nb_word_token\"] = df[\"avis_word_token\"].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on regarde la moyenne, l'écart type, les quartiles de ces métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[[\"nb_char\", \"nb_word_token\", \"nb_sent_token\" ]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "une fois qu'on a divisé notre texte en une liste de mots, on peut faire plusieurs opérations de netoyage \n",
    "- retirer la ponctuation \n",
    "- mettre tous les caractères en minuscules (peut aussi être fait avant la tokenization)\n",
    "- enlever les stopwords (mots sans apport pour comprendre le sens de la phrase)\n",
    "- lemmatiser ou stemmer afin de regrouper deux termes proches en un terme unique : \n",
    "    - personnes -> personne\n",
    "    - conduisent, conduis, etc.. -> conduire\n",
    "    \n",
    "Ces étapes sont réalisées dans la partie 2 : extraction de topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on peut ensuite \"vectoriser ces listes de mots afin de les rendre intelligible par une machine, \n",
    "il existe plusieurs méthode de vectoriser \n",
    "    - la matrice de term frequency \n",
    "    - la matrice tf-idf\n",
    "    - les word embeddings \n",
    "    \n",
    "Une fois que ces documents sont vectorisés, on peut utiliser ces features numériques nouvellement crées pour faire de la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressource: un article (en anglais) bien fait qui montre comment calculer la matrice TF et TF-IDF \"form scratch: cratch : https://towardsdatascience.com/text-summarization-using-tf-idf-e64a0644ace3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer automatiquement ces matrices, il existe différentes librairies. On utilise ici la librairie sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matrice de term frequency (matrice d'occurrence de termes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![term_doc_matrix.png](./images/term_doc_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque document est composé d'un certains nombre de mots. L'ensemble de tous les mots distincts présents dans les documents consititue le vocabulaire du corpus (corpus = ensemble des documents). \n",
    "La term-frequency matrix est une matrice avec une ligne par document et une colonne par mot du vocabulaire. \n",
    "Pour chaque document, les colonnes donne le nombre de fois où le mot apparait dans le document. \n",
    "C'est l'approche qu'on appelle souvent \"bag of words\" ou sac de mots en français. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous on calcule la matrice Term frequency à l'aide de la librairie sklearn, qui comprend un modèle \"CountVectorizer\", qui'il faut entraîner sur le corpus de données (la liste des avis). Une fois le modèle entrainé, on l'applique (avec la métode transform) sur le même corpus de données. \n",
    "Un paramètre utile au modèle CountVectorizer est \"min_df\", qui correspond au minumum de fois où un mot doit apparaitre dans le corpus afin d'être pris en compte dans la matrice. Il est par défaut à 1, mais en l'augmentant, on peut réduire considérablement le nomnbre de colonnes de la matrice et donc se débarrasser des termes qui apparaissent trop peu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 15).fit(df[\"Avis\"])\n",
    "tf_matrix = vect.transform(df[\"Avis\"])\n",
    "print(\"TF-Matrix:\\n{}\".format(repr(tf_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Nombre de features: {}\".format(len(feature_names)))\n",
    "print(\"Les 20 premières features:\\n{}\".format(feature_names[:20]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour visualiser la matrice, on la transforme en dataframe: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataframe = pd.SparseDataFrame(tf_matrix, columns = feature_names).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tf_dataframe[\"être\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe ce que l'on appelle une matrice sparse, ce qui signifie que la majorité des termes sont à 0.\n",
    "On voit par exemple que les documents 3 et 4 ont chacun une fois le mot \"être\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut regarder quels sont les termes les plus fréquents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_words = tf_matrix.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La matrice tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfidf_matrix.png](./images/tfidf_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice TF-IDF est très similaire dans son principe à la matrice TF. Elle a le même format: une ligne par document et une colonne par mot du vocabulaire. Chaque \"case\" de la matrice sera calculée à partir de la case la matrice TF, mais sera pondérée par l'IDF (inverse document frequency). Cette pondération permet de prendre en compte la fréquence d'occurence d'un terme dans l'ensemble des documents (le corpus). L'idée derrière cette pondération est qu'un terme qui apparait dans un très grand nombre de document n'apporte pas beaucoup d'information pour décrire un document en particulier. Par exemple, dans notre cas, le mot \"avis\" apparait dans quasiment tous nos documents, il aura donc une fréquence d'apparition dans le corpus élevé et donc un IDF (son inverse) faible. \n",
    "\n",
    "Pour résumer, pour un mot donné d'un document donné, le TF-IDF: \n",
    "\n",
    "- augmente avec le nombre d'occurrences du mot dans le document\n",
    "- diminue avec le nombre d'occirrences du mot dans le corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = TfidfVectorizer(min_df = 15, norm = None).fit(df[\"Avis\"])\n",
    "tfidf_matrix = vect2.transform(df[\"Avis\"])\n",
    "print(\"TF-Matrix:\\n{}\".format(repr(tf_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect2.get_feature_names()\n",
    "print(\"Nombre de features: {}\".format(len(feature_names)))\n",
    "print(\"Les 20 premières features:\\n{}\".format(feature_names[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans surprise, on obtient les mêmes features qu'avec la matrice TF. Regardons mainteant quelques lignes de cette matrice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_dense = tfidf_matrix.todense()\n",
    "tfidf_matrix_dense[tfidf_matrix_dense == 0] = np.nan\n",
    "mean_words = np.nanmean(tfidf_matrix_dense, axis=0)\n",
    "words_mean_tfidf = [(word, mean_words[0, idx]) for word, idx in vect2.vocabulary_.items()]\n",
    "words_freq =sorted(words_mean_tfidf, key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est intéressant de comparer ici les termes remontés avec la matrice TF et ceux avec la matrice TFIDF. La matrice TF remonte beaucoup de termes \"inutiles\" (de, et, etc...), alors que la matrice TFIDF remonte des termes plus intéressants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dataframe = pd.SparseDataFrame(tfidf_matrix, columns = feature_names).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de word embeddings of word2vec\n",
    "\n",
    "A propos de word2vec: développé par une équipe de recherche de Google (article de 2013 disponible ici https://arxiv.org/abs/1301.3781), word2vec est un algorithme permettant de reprénter chaque mot dans un espace vectoriel à n dimensions (généralement n est fixé dans une valeur comprise entre 100 et 400). Les vecteurs des différents mots sont \"appris\" à l'aide d'un réseau de neurone artificiel. Ces vecteurs, appelés \"word embeddings\", permettent: \n",
    "- de rendre compte des proximités des mots dans le langage naturel (deux mots proches dans le langage, médecin et hopitaux, seront proches dans l'espace vectoriel) \n",
    "- de traduire certaines proprités linguistiques du langage naturel en propriétés mathématiques (cf. exemples dans illustration ci-dessous)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word2vec.png](./images/word2vec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement du modèle à partir du texte des avis Cada. Les paramètres à fixer sont: \n",
    "- size: la taille de l'espace vectoriel (le nombre de dimensions de chaque vecteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"avis_word_token\"].tolist()\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple de vecteur pour un mot donné (vous pouvez changer le mot entre guillements et voir les variations des vecteurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['avis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quelques exemples de calculs des mots les plus similaires, en utilisant la fonction méthode \"most_similar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"médecin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"maire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.most_similar(\"demande\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEL6x0Kfsdvmbf+E371X9g",
   "include_colab_link": true,
   "name": "ami_ia-NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
