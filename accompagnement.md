# Programme des ateliers de formation techniques

L'AMI IA se caractérise aussi par un accompagnement via des sessions de formation. Ce document présente les différents ateliers réalisées et leurs supports.

## Session 1 : Introduction à l'intelligence artificielle, 4 février.

### Plénière : panorama de l'IA (1h)

- aperçu de cas d'usage de l'IA
- présentation des notions clés en IA 

### IA literacy : 2 kiosques (3 x 20 min) 

- Préparation des données entraînement, choix de l'algo (Paul-Antoine)
- Réussir sa campagne d'annotation (Kim)
- Evaluer le succès de votre projet IA : les indicateurs de performances (Julien)

### Atelier de préparation de l'arrivée du prestataire (20 min)

### Supports

- [les slides de présentation](https://speakerdeck.com/etalabia/pleniere-ami-a-2-4-fevrier-2020-matin)
- [le questionnaire de satisfaction](https://framaforms.org/questionnaire-satisfaction-pleniere-ami-ia-du-4-fevrier-1580823697)


## Session 2 : Vis ma vie de data scientist, 11 juin.

L'objectif de cette formation est de vous faire découvrir le déroulement et les outils d'un projet de data science à travers trois cas d'études.

Pour commencer, cliquez simplement sur le lien de l'atelier qui vous intéresse ci-dessous. Un [notebook](https://fr.wikipedia.org/wiki/Notebook_(programmation)) s'ouvrira alors dans [Google Colaboratory](https://colab.research.google.com/).

- **Introduction :** [Notebook introduction aux outils du data scientist](https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/ami_ia_introduction_jupyter_notebook.ipynb) 

- **Atelier 1 :** [Notebook introduction à la data visualisation](https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/ami_ia_dataviz_rr.ipynb) et [Rediffusion de la session de formation](https://visio.incubateur.net/playback/presentation/2.0/playback.html?meetingId=6f3acca485c398a1c9632e1efb38012581acde9c-1591880321574)

- **Atelier 2 :** [Notebook introduction au traîtement du langage naturel](https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/ami_ia_NLP_cada.ipynb) et [Rediffusion de la session de formation](https://minio.lab.sspcloud.fr/strainel/spyrales_conf8_nlp_cada.mp4)

- **Atelier 3 :** [Notebook introduction au machine learning](https://colab.research.google.com/github/etalab-ia/ami-ia/blob/master/notebooks/intro-ML.ipynb) et [Rediffusion de la session de formation](https://visio.incubateur.net/playback/presentation/2.0/playback.html?meetingId=1f8a35fb378e0a4d1cc0d26bec5454f8ceaf88ac-1591880656126)

## Session 3 : Explicabilité des algorithmes, 9 juillet 

Cette session est organisée avec Simon Chignard et Soizic Penicaud qui travaillent sur la transparence des algorithmes publics au sein d'Etalab, et Clément Hénin, doctorant à l'INRIA dont les recherches portent sur l'explicabilité des algorithmes. 

#### Programme : 
- Fondements théoriques de l'explicabilité
- Ateliers d'identification des enjeux d'explicabilité dans les projets 
- Conclusion et mise en commun 

#### Ressources : 
- [Le support de présentation](https://github.com/etalab-ia/ami-ia/blob/master/images/AMI_IA_2_Atelier_%233_9juillet2020.pdf)
- [L'enregistrement vidéo de la session](https://visio.incubateur.net/playback/presentation/2.0/playback.html?meetingId=227cbb7905fce775cffaaa01d64d65a8c89bff85-1594295133544)
- [Matrice d'explication des algorithmes à remplir par groupe](./images/matrice_explication.docx)
- [Un exemple de matrice d'explication remplie](./images/matrice_explication_exemple_score_coeur.docx)
- [Le guide Etalab sur la transparence des algorithmes publics](https://guides.etalab.gouv.fr/algorithmes/)



## Session 4 : Identifier et prévenir les biais dans vos projets, 8 octobre 

#### Ressources

Ci-dessous, les liens pour consulter ou télécharger les 3 présentations qui ont été faites en plénière :
 
 
 - Le lien de rediffusion de la séance: https://visio.incubateur.net/playback/presentation/2.0/playback.html?meetingId=227cbb7905fce775cffaaa01d64d65a8c89bff85-1602156756613 
 
- L’introduction par Valérie Fontaine et Gaëtan Goldberg du Défenseur des droits : https://speakerdeck.com/etalabia/20200810-atelierbiaisami-ia-ddd
 
- La présentation de Philippe Besse : https://speakerdeck.com/etalabia/20200810-atelierbiaisami-ia-ph-besse
 
- La présentation de Jean-Marie John-Mathews https://speakerdeck.com/etalabia/20200810-atelierbiaisami-ia-john-mathews

- Le questionnaire d'identication des biais dans votre projet
 
En complément, voici quelques ressources en lien avec l’atelier :
- L’article du Défenseur des droits : https://www.defenseurdesdroits.fr/sites/default/files/atoms/files/synth-algos-num-05.06.20.pdf
- Livre blanc de la commission européenne : https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence-feb2020_fr.pdf
Lignes directrices de la commission européenne pour une IA digne de confiance : https://op.europa.eu/fr/publication-detail/-/publication/d3988569-0434-11ea-8c1f-01aa75ed71a1/prodSystem-cellar/language-fr/format-PDF
- Le dépôt de Philippe Besse incluant les exemples/cas pratiques présentés en plénière : https://github.com/wikistat/Fair-ML-4-Ethical-AI et l’article associé https://hal.archives-ouvertes.fr/hal-02616963

 

